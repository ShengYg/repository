---
layout: post
title:  "个人项目"
date:   2018-03-01 14:00:00 +0800
categories: [projects]
tags: []
description: 个人项目总结，深度学习、机器学习
---

## 项目介绍
- 项目一：利用深度学习的方法，检测并识别快递单上的手写体电话号码。
  - 第一部分定位，在caffe框架下，利用检测算法faster-rcnn，定位电话号码的位置。解决小物体检测、样本不均衡、定位框不准确的问题。
  - 第二部分识别，在pytorch框架下，基于概率模型设计CNN，识别电话号码。解决样本不均衡、过拟合的问题。
  - 碰到两个网络不兼容的问题，检测网络的误差会在识别网络中放大，造成结果很差。最后通过在识别网络中主动引入背景噪声，加强其抗噪能力。
- 项目二：利用深度学习，处理双目视觉的视差估计
  - 简介：传统的视差估计包含动态规划，无法有效并行运算，速度慢。利用深度学习能达到实时效果。
  - 利用torch框架设计端到端的全卷积网络。
  - 训练中碰到网络过深，难以训练的问题。通过引入多尺度信息、BN层、加入多个中间loss层解决。
- Kaggle比赛：Mercedes-Benz
  - 简介：给定汽车的一系列数据，进行回归任务，预测车的安全指数。
  - 利用Python scikit-learn分析数据，清洗数据。
  - 用xgboost、gbdt、线性回归等基学习器学习；尝试bagging，stacking集成。


## 项目一：2D人脸年龄变换
### 目的：
同一个人不同年龄的人脸，脸上皱纹、头发颜色。

### 主体方法：
#### GAN（失败）
##### 网络结构：
- CGAN，训练时输入人脸与年龄（标签），测试时根据年龄，得到不同年龄的人；
- encoder-decoder，保持是同一个人。
##### 缺点
- 分辨率不够高，提升分辨率训练难度增加，时间变长；
- 存在畸变。

#### 风格迁移（成功）
思路：青年人作为内容图，老年人作为风格图，将老年人的风格迁移过来，使人脸变老。
难点：产生明显的扭曲、锯齿（通常用风格迁移改变自然环境，因为环境对扭曲、锯齿的容忍度更大）。
##### 网络结构：
- 人脸（不变颜色，变纹理）
    - 颜色：建立风格库，选中颜色最接近的，改变色度，使颜色统一。
    - 纹理：MRFCNN，基于块的匹配（此处省略具体步骤），锯齿状不明显。
    - 问题：锯齿状噪声（gram&匹配）；错误匹配（多分辨率，阈值）
- 头发（变颜色，不变纹理，deep photo transfer）
    - mask，对应区域转换
    - Matting Laplacian：将输入的RGB图片经过局部仿射变换得到**灰度抠图**，可以理解为得到了纹理信息。这种纹理信息在风格迁移过程中不应该变化，所以将它作为惩罚项加入损失函数。
    - 问题：头发形状扭曲（加mask）
- 其他：
    - 人脸与头发分割网络，人脸分割后用dlib landmark纠正。
    - 人脸对齐：德劳内三角化（任意点不在其他三角形的外接圆中）；维诺图（相邻点的中垂线切割整个图，连接所有相邻点得到德劳内三角）
    - 人脸融合：泊松融合，在梯度上进行融合。（**融合时避免肤色的变化**）




## 项目二：快递单上手写体电话号码的识别
### 1. 简介
对于一张完整的快递单的扫描件，检测并识别上面的手写体电话号码。项目分为两个步骤：1、检测号码位置；2、识别一串号码（序列识别）。由于数据来源于快递单复印件的扫描件，背景比较模糊，基于点线的传统方法鲁棒性不强，因此采用深度学习的方法。

### 2. 背景及意义
快递公司中转站需要检查快递单上发件人、收件人的号码，检验其是否在黑名单中。原来这一部分工作是由人工完成，现在可以自动化完成。

难点：
1. 数据来源于快递单复印件的扫描件，背景比较模糊，干扰项较多
2. 对号码的快速检测
3. 序列识别

### 3. 方法介绍
- 检测网络faster-rcnn
  - 号码属于小物体（roipooling 整除带来误差），需要减少中间的pooling次数。为了不损失精度，加深网络。调整anchor参数。
  - ohem在线难例搜索，为什么？1、负样本过多，2、干扰项很严重，如其他号码
- 识别网络
  - 根据条件概率设计。假设号码最长是12位，网络的结构是：输入一张图片，输出13位（前12位得到识别的数字结果，最后1位是号码长度）。
  - 过拟合，（不需要dropout、bn，只需要生成短号码）
- 网络连接
  -  定位框不是非常准确，影响后续识别结果（尤其是加入复杂背景）。
  -  样本框扩大，加入扰动。

### 4. 额外思考
最重要的一点：两个模型的结合
- 问题：定位不准的时候，后面的识别网络也无法正常工作（再加上背景干扰）
- 开始：提升定位精度，有限
- 后来：1、干脆识别网络中引入噪声，提升它的鲁棒性（类似random-crop，增大样本，过拟合）；2、定位网络中也放大框，进行训练；3、测试时定位的输出进行扰动，产生多个候选，进行识别，投票。

缺陷：
1. 不均匀的号码
2. 数字位移（图片中第一位是5，结果中第二位是5）
3. 时间：定位0.073s，识别0.025s，定位可以采用更快速的网络。

为何不使用LSTM识别号码：
1. 背景干扰严重：使用标准数据有结果（？？），使用快递单不收敛。
2. 增加长度，收敛变慢（？？）

如何使用LSTM设计：
- 关键点：如何将图片转换成序列？将图片沿着Y方向切割，形成切片，经过双向LSTM，最后用CTCloss识别。
- 巧妙之处：一个数字可能被切成多片，双向LSTM会考虑到前后的联系，最近的影响大，最远的影响小，有效的识别出数字。
- CTCloss：应用在语音识别领域，用于处理输入长度大于输出的loss。




## 项目三：基于深度学习的视差估计（毕业设计）
- 概要：传统方法中包含动态规划，比较耗时。利用深度学习，设计端到端的网络，输入左右两张图，输出视差图。
- 数据集：弗莱堡大学driving数据集，用3D软件仿真得到的街景数据，包括视差、光流、语义分割等等。
- 网络结构：输入两张图，各自经过若干卷积层，拼接，反卷积至原来的分辨率。反卷积的过程中加入正向卷积的信息。（看到一篇文章做光流，参考其结构）
- 错误率4.50%（另一篇论文2.61%），速度960*640的图片0.06s（另一篇论文0.78s），TitanX。

一些细节：
1. 不收敛，像是梯度消失：设置多个loss，依次训练。
2. 多尺度feat的叠加

第一篇论文相关，为了加速一篇论文中的算法：
1. 加速，半全局匹配：
能量函数是关于位置、视差的函数，对相邻像素视差超过1的点进行惩罚。在2D范围内求解最小值是NP难的，因此沿着某个方向进行动态规划。比较耗时（0.34+0.44=0.78s)
2. 网络结构：左右图中各选取一个patch，通过网络计算cost。网络存在重复计算。




## 一个kaggle竞赛题
#### 题目
benz，一个回归任务，评价标准r2。只给了数据，没有数据的具体意义。
#### 方法
1. 预处理：多分类特征独热码（否则1-3距离大于1-2距离）；5折交叉验证，产生数据集。并没有对数据做额外处理（350类，每个都是二值，信息少，含有冗余特征，需要降维）。
2. 训练基训练器：xgboost，rm，svr，kmeans（观察数据得到）。看了相关blog，学习高效的手动调参；为了集成，hyperopt自动调参，生成一系列学习器及其**准确率**、**特征**；
3. 尝试两种集成，先是采用bagging，效果不佳。（**设计考虑因素**：bagging在复杂模型的基础上构建效果更佳，偏差方差角度，类似RF树很深，因此内部需要查找最佳）内部类似特征选择的包装法，选择的对象是学习器：1、随机选取一部分学习器，取其中准确率最大的k（5）个，将预测特征求平均，并得到结果best-score；2、遍历一遍学习器，将特征与之前的平均特征加权（weight自动调参），得到更好的best-score，记录学习器与权重；3、重复步骤2，直到找不到更大的best-score；4、得到每一次应该选择的学习器与对应权重参数。
4. 发现一些特点：1、xgboost的max_depth不大，原因是数据信息量不大，或是数据特征存在冗余，需要进行特征选择（PCA，RF），同时升维；2、集成没有明显效果，原理上没问题，但是不停地贪心加入学习器，会出现过拟合，类似于树太深（限制学习器个数，集成费时间，放弃了）。
5. stacking和求平均。1、xgboost训练（XGB效果不错，单独放在一支）；2、GBRT+线性回归，stacking叠加(**设计考虑因素**：基学习器**差异大准确高**（不同参数，特征），次学习器为避免过拟合选择LR；k-fold，测试集的输出作为新的输入)。二者加权取平均，权重由尝试得来，交叉验证。

总结：
1. 如何选特征（删除冗余特征）？
- Forward Selection（贪婪搜索）。抽样部分特征，每个特征有权重，随机森林（不容易过拟合）训练，得到结果。结果超过平均（至少30轮），相应特征的权重增加，不超过平均就减少。当某个权重超过阈值时，加入top_feats。最终的特征由top_feats构成。！！容易过拟合。选择多种模型与抽样参数（每次抽样个数），总的top_feats在它们的基础上平均
- PCA，svd
2. 收获：1、特征选择很重要；2、这个比赛对模型融合的要求不高，按照理论操作；3、代码层次，方便加入新学习器；4、逛讨论区，接触新的思路

## other
- 机器学习or深度学习：1、调参。机器学习理论性更强；深度学习靠经验，先有成果后写原因。应用层面，个人层面（思维能力、成就感）。
